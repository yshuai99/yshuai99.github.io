<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://yshuai99.github.io</id>
    <title>yshuai</title>
    <updated>2022-05-24T19:41:35.355Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://yshuai99.github.io"/>
    <link rel="self" href="https://yshuai99.github.io/atom.xml"/>
    <subtitle>Work for a better world</subtitle>
    <logo>https://yshuai99.github.io/images/avatar.png</logo>
    <icon>https://yshuai99.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, yshuai</rights>
    <entry>
        <title type="html"><![CDATA[SELECT queries -01]]></title>
        <id>https://yshuai99.github.io/post/db01/</id>
        <link href="https://yshuai99.github.io/post/db01/">
        </link>
        <updated>2022-05-22T21:05:52.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://yshuai99.github.io/post-images/1653352693708.png" alt="" loading="lazy"></figure>
<h2 id="simple-select">Simple Select</h2>
<pre><code class="language-SQL">select classNo, className, institute
from Class

select distinct institute
from Class

select * 
from Class

select classNo, className, institute
from class
where grade=2015

select studentNo, studentName, birthday
from student
where year(getdate())-year(birthday) &gt;= 19

select studentNo, courseNo, score
from score
where score between 80 and 90

select studentNo, courseNo, score
from score
where score not between 80 and 90

select studentNo, courseNo, score
from score
where courseNo in ('001','005','003')

select studentNo, courseNo, score
from score
where courseNo='001' or courseNo='005' or courseNo='003'

select studentName, native, classNo
from student
where native not in ('南昌','上海')

select * 
from course
where priorCourse is Null

select * 
from course
where priorCourse is not Null

select *
from class
where className LIKE '%会计%'

SELECT studentNo, studentName
FROM Student
WHERE studentName LIKE '王__'

SELECT studentName, native, classNo
FROM Student
WHERE native!='南昌 ' AND native!='上海'

SELECT studentNo, studentName, classNo, birthday
FROM Student
WHERE sex='女'
ORDER BY classNo, month (birthday) DESC

SELECT studentNo, studentName, birthday
FROM (SELECT * FROM Student WHERE sex='女') AS a
WHERE year (birthday)=1999

SELECT studentNo , count(*) 门数 , avg(score) 平均分, max(score)最高分
FROM Score
GROUP BY studentNo
HAVING avg (score)&gt;=80

SELECT studentNo, studentName, native, b.classNo , className
FROM Student a , Class b
WHERE a.classNo=b.classNo AND institute='会计学院'

SELECT a.studentNo, studentName
FROM Student a, Course b,Score c
WHERE b.courseNo=c.courseNo 
AND c.studentNo=a.studentNo AND b.courseName='计算机原理'

SELECT a.studentNo, studentName, b.courseNo, b.score, c.courseNo, c.score
FROM Student a , Score b, (SELECT * FROM Score WHERE courseNo='002') c
WHERE b.courseNo='001'
AND a.studentNo=b.studentNo 
AND a.studentNo=c.studentNo

SELECT a.studentNo, studentName, b.courseNo, b.score, c.courseNo, c.score
FROM Student a , Score b , Score c
WHERE b.courseNo='001' AND c.courseNo='002'
AND a.studentNo=b.studentNo AND b.studentNo=c.studentNo
ORDER BY a.studentNo

SELECT a.studentNo , studentName , sum(creditHour)
FROM Student a , Course b , Score c
WHERE a.studentNo=c.studentNo AND c.courseNo=b.courseNo AND score&gt;=60
GROUP BY a.studentNo, studentName
HAVING sum(creditHour)&gt;=28
ORDER BY a .studentNo

SELECT studentName
FROM Student
WHERE Student. studentNo IN 
	(SELECT Score.studentNo FROM Score)


SELECT studentNo, studentName, classNo
FROM Student
WHERE studentNo IN
	(SELECT studentNo FROM Score WHERE courseNo IN
		(SELECT courseNo FROM Course WHERE courseName LIKE '%系统'))

SELECT studentNo, courseNo, score
FROM Score
WHERE score &gt;ALL(SELECT score 
					FROM Score WHERE courseNo='002' )

SELECT studentNo, courseNo, score
FROM Score
WHERE score =(SELECT max(score) FROM Score)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introduction]]></title>
        <id>https://yshuai99.github.io/post/introduction/</id>
        <link href="https://yshuai99.github.io/post/introduction/">
        </link>
        <updated>2022-05-19T17:38:45.000Z</updated>
        <summary type="html"><![CDATA[<p>Here is Yuxin Shuai. I am working on quantitative trading and data analysis.</p>
]]></summary>
        <content type="html"><![CDATA[<p>Here is Yuxin Shuai. I am working on quantitative trading and data analysis.</p>
<!-- more -->
<p>Here is the contents of this blog:</p>
<h2 id="small-projects-for-fun">Small projects for FUN:</h2>
<ul>
<li>
<p><a href="https://yshuai99.github.io/post/difflib/">Difference visualization between two csv file</a></p>
</li>
<li>
<p><a href="https://yshuai99.github.io/post/crawler01/">Web crawler with Python -01 (douban movies TOP 250)</a></p>
</li>
</ul>
<h2 id="sql-exercise">SQL exercise:</h2>
<ul>
<li><a href="">DML exercise -01</a></li>
<li><a href="">DML exercise -02</a></li>
</ul>
<h2 id="technological-analysis">Technological analysis:</h2>
<ul>
<li><a href="https://yshuai99.github.io/post/hollween-effect-strategy/">Holloween effect strategy</a></li>
<li><a href="https://yshuai99.github.io/post/movie-industry-stocks-timing/">Movie industry stocks timing</a></li>
<li><a href="https://yshuai99.github.io/post/golden-cross-strategy/">Golden cross strategy</a></li>
<li><a href="https://yshuai99.github.io/post/basic/">Basic MACD strategy</a></li>
<li><a href="https://yshuai99.github.io/post/triangular-arbitrage/">Triangular Arbitrage </a></li>
<li><a href="https://yshuai99.github.io/post/pairs-trading-in-progress_/">Pairs Trading</a></li>
</ul>
<h2 id="reports">Reports:</h2>
<ul>
<li>
<p><a href="https://yshuai99.github.io/post/the-performance-of-macroeconomic-factors-timing-in-chinese-stock-market-/">The performance of macroeconomic factors timing in Chinese stock market </a></p>
</li>
<li>
<p><a href="https://yshuai99.github.io/post/fundamental-factors/">Effectiveness of Some Fundamental Factors in China Stock Market</a></p>
</li>
</ul>
<h2 id="projects">Projects:</h2>
<ul>
<li>[Fama-Macbeth Regression (In progress)]</li>
<li>[Mean-Variance portfolio with optimization (In progress)]</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Difference visualization between two csv file]]></title>
        <id>https://yshuai99.github.io/post/difflib/</id>
        <link href="https://yshuai99.github.io/post/difflib/">
        </link>
        <updated>2022-04-01T10:01:55.000Z</updated>
        <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>By using the <a href="https://docs.python.org/3/library/difflib.html">difflib library</a>, the difference between two csv could be visualized:</p>
<figure data-type="image" tabindex="1"><img src="https://yshuai99.github.io/post-images/1653267133053.jpg" alt="" loading="lazy"></figure>
<h1 id="visualization">Visualization</h1>
<pre><code class="language-python">import sys
import difflib
 
 
def readfile(file1):
    try:
        fd=open(file1,&quot;r&quot;)
        text=fd.read().splitlines() 
        return text
    except Exception as e:
        print(&quot;read file error&quot;)
        print(e)
        sys.exit()
 
 
 
def Compare(file_1,file_2):
    if file_1 ==&quot;&quot; or file_2 == &quot;&quot;:
        print(&quot;file 1 or file 2 not empty&quot;)
        sys.exit()
 
    text1=readfile(file_1)
    text2=readfile(file_2)
 
    diff=difflib.HtmlDiff() 
    result=diff.make_file(text1,text2)  
 
    try:
        fd_diff=open(&quot;diff.html&quot;,&quot;w&quot;)
        fd_diff.write(result)
 
    except Exception as e:
        print(&quot;write html file error&quot;)
        print(e)
        sys.exit()
 
 
if __name__ == '__main__':
    Compare(&quot;original.csv&quot;,&quot;updated.csv&quot;)
</code></pre>
<h1 id="an-easy-way-to-export-the-difference-into-new-csv-file">An easy way to export the difference into new csv file</h1>
<pre><code class="language-python">with open('original.csv', 'r') as csv1, open('updated.csv', 'r') as csv2:  # Import CSV files
    import1 = csv1.readlines()
    import2 = csv2.readlines()

with open('data_diff.csv', 'w') as outFile:         # Create CSV file with differences
    for row in import2:
        if row not in import1:
            outFile.write(row)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Web crawler with Python -01 (Douban movies TOP 250) ]]></title>
        <id>https://yshuai99.github.io/post/crawler01/</id>
        <link href="https://yshuai99.github.io/post/crawler01/">
        </link>
        <updated>2022-03-11T08:10:47.000Z</updated>
        <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>A simple  crawler, the target is finding the top 250 rated movies listed in Douban (A Chinese movie rating website) and the web page is: http://movie.douban.com/top250/.</p>
<p>Read the html first:</p>
<ul>
<li>The title of the movies is stored in &quot;li&quot; class:<br>
<img src="https://yshuai99.github.io/post-images/1653244323285.png" alt="" loading="lazy"></li>
<li>The <strong>next page</strong> link is stored in the &quot;next&quot; class:<br>
<img src="https://yshuai99.github.io/post-images/1653244382592.png" alt="" loading="lazy"></li>
</ul>
<h1 id="code">Code</h1>
<p>Then come up with the code:</p>
<pre><code class="language-python">#!/usr/bin/env python
# encoding=utf-8

import codecs
import requests
from bs4 import BeautifulSoup

DOWNLOAD_URL = 'http://movie.douban.com/top250/'

# User-Agent
def download_page(url):
    return requests.get(url, headers={
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'
    }).content

# find the title of the movies

def parse_html(html):
    soup = BeautifulSoup(html)
    movie_list_soup = soup.find('ol', attrs={'class': 'grid_view'})

    movie_name_list = []

    for movie_li in movie_list_soup.find_all('li'):
        detail = movie_li.find('div', attrs={'class': 'hd'})
        movie_name = detail.find('span', attrs={'class': 'title'}).getText()

        movie_name_list.append(movie_name)

# It has ten pages with 25 movies per page, find the next page link
    next_page = soup.find('span', attrs={'class': 'next'}).find('a')
    if next_page:
        return movie_name_list, DOWNLOAD_URL + next_page['href']
    return movie_name_list, None


def main():
    url = DOWNLOAD_URL

    with codecs.open('laocheng', 'wb', encoding='utf-8') as fp:
        while url:
            html = download_page(url)
            movies, url = parse_html(html)
            fp.write(u'{movies}\n'.format(movies='\n'.join(movies)))


if __name__ == '__main__':
    main()
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Triangular Arbitrage]]></title>
        <id>https://yshuai99.github.io/post/triangular-arbitrage/</id>
        <link href="https://yshuai99.github.io/post/triangular-arbitrage/">
        </link>
        <updated>2022-01-31T23:14:53.000Z</updated>
        <summary type="html"><![CDATA[<p>Here is the R code and example for foreign, exchange rate and triangular arbitrage.</p>
]]></summary>
        <content type="html"><![CDATA[<p>Here is the R code and example for foreign, exchange rate and triangular arbitrage.</p>
<!-- more -->
<h1 id="example-1">Example 1</h1>
<figure data-type="image" tabindex="1"><img src="https://yshuai99.github.io/post-images/1645712729898.png" alt="" loading="lazy"></figure>
<h2 id="code">code</h2>
<pre><code class="language-R">
f.obj &lt;- c(-1,-1,-1,-1,1.3495277,0,0,0,1.52207,0,0,0,0.942507,0,0,0,0.9891197,               0,0,0)

# Create constraint matrix B
f.con &lt;- matrix(c(-1,-1,-1,-1,1.3495277,0,0,0,1.52207,0,0,0,0.942507,0,0,0,                               0.9891197,0,0,0,
-1,-1,-1,-1,1.3495277,0,0,0,1.52207,0,0,0,0.942507,0,0,0,0.9891197,0,0,0,
0.741,0,0,0,-1,-1,-1,-1,0,1.1248594,0,0,0,0.6978367,0,0,0,0.7320644,0,0,
0,0.657,0,0,0,0.889,0,0,-1,-1,-1,-1,0,0,0.6195787,0,0,0,0.6501951,0,
0,0,1.061,0,0,0,1.433,0,0,0,1.614,0,-1,-1,-1,-1,0,0,0,1.049318,
0,0,0,1.011,0,0,0,1.366,0,0,0,1.538,0,0,0,0.953,-1,-1,-1,-1
), nrow=6, byrow=TRUE)

# Right hand side for the constraints
f.rhs &lt;- c(1, 10, 0, 0, 0, 0)

# Direction of the constraints
f.dir &lt;- c(&quot;&gt;=&quot;, &quot;&lt;=&quot;, &quot;=&quot;, &quot;=&quot;,&quot;=&quot;,&quot;=&quot;)
lp(&quot;max&quot;,f.obj,f.con,f.dir,f.rhs)
lp(&quot;max&quot;,f.obj,f.con,f.dir,f.rhs)$solution
</code></pre>
<p>The result is:</p>
<figure data-type="image" tabindex="2"><img src="https://yshuai99.github.io/post-images/1645713595762.png" alt="" loading="lazy"></figure>
<p>According to the result, the trading actions are:</p>
<ul>
<li>USD to EUR: 3756.446</li>
<li>EUR to GBP: 2783.527</li>
<li>GBP to USD: 2474.555</li>
</ul>
<h1 id="example-2">Example 2:</h1>
<p>In the above example, we implicitly assumes that the currencies can be bought or sold at the same price. In real markets, there is always a gap between the price a buyer pays for a security and the amount the seller collects called the bid-ask spread. We now model this real-life situation, where we can only purchase each currency at their ask prices or sell them at their bid prices. Consider the following bid/ask rates among the fivve currencies:<br>
<img src="https://yshuai99.github.io/post-images/1645713718773.png" alt="" loading="lazy"><br>
<img src="https://yshuai99.github.io/post-images/1645713736262.png" alt="" loading="lazy"><br>
Develop a new LP to detect if there is arbitrage opportunities in these bid/ask rates via the LP solver.</p>
<h2 id="code-2">Code:</h2>
<pre><code class="language-R">f.obj &lt;- c(-1,-1,-1,-1,1.3422819,0,0,0,1.5174507,0,0,0,0.9380863,0,0,0,                       0.9832842,0,0,0)

# Create constraint matrix B
f.con &lt;- matrix(c(-1,-1,-1,-1,1.3422819,0,0,0,1.5174507,0,0,0,0.9380863,0,0,0,                            0.9832842,0,0,0, -1,-1,-1,-1,1.3422819,0,0,0,                                 1.5174507,0,0,0,0.9380863,0,0,0,0.9832842,0,0,0,
                            0.745,0,0,0,-1,-1,-1,-1,0,1.117318,0,0,0,0.694927,                            0,0,0,0.729927,0,0,0,0.659,0,0,0,0.8895,0,0,-1,-1,                            -1,-1,0,0,0.6176652,0,0,0,0.6493506,0,0,0,1.066,0,                            0,0,1.439,0,0,0,1.619,0,-1,-1,-1,-1,0,0,0,                                    1.043841, 0,0,0,1.017,0,0,0,1.37,0,0,0,1.54,0,0,0,                            0.958,-1,-1,-1,-1
                            ), nrow=6, byrow=TRUE)

# Right hand side for the constraints
f.rhs &lt;- c(1, 10, 0, 0, 0, 0)

# Direction of the constraints
f.dir &lt;- c(&quot;&gt;=&quot;, &quot;&lt;=&quot;, &quot;=&quot;, &quot;=&quot;,&quot;=&quot;,&quot;=&quot;)

lp(&quot;max&quot;,f.obj,f.con,f.dir,f.rhs)
lp(&quot;max&quot;,f.obj,f.con,f.dir,f.rhs)$solution
</code></pre>
<p>The result is:<br>
<img src="https://yshuai99.github.io/post-images/1645713945723.png" alt="" loading="lazy"><br>
According to the results above, the trading actions are:</p>
<ul>
<li>USD to EUR: 833.9974</li>
<li>EUR to CHF: 621.3280</li>
<li>GBP to USD: 556.1943</li>
<li>CHF to CAD: 894.0910</li>
<li>CAD to GBP: 856.5392</li>
</ul>
<h1 id="example-3">Example 3:</h1>
<p>The LP method is fine for small size problem. However, for large size problem special-purpose method is needed. Calculate the arbitrage by usingthe Bellman-Ford method.<br>
<img src="https://yshuai99.github.io/post-images/1645714073218.png" alt="" loading="lazy"></p>
<h2 id="code-3">Code</h2>
<pre><code class="language-R">#Initialize the graph
initial.graph &lt;- make_empty_graph(5,directed = T)
#Create edges
graph.edges &lt;- matrix(c(1,2,
                                        1,3,
                                        1,4,
                                        1,5,
                                        2,1,
                                        2,3,
                                        2,4,
                                        2,5,
                                        3,1,
                                        3,2,
                                        3,4,
                                        3,5,
                                        4,1,
                                        4,2,
                                        4,3,
                                        4,5,
                                        5,1,
                                        5,2,
                                        5,3,
                                        5,4
                                        ), nrow=20, byrow=TRUE)

#create weights
graph.weights &lt;- matrix(c(-log(0.9100000),
                                           -log(0.7640000),
                                           -log(1.0280000),
                                           -log(1.320),
                                           log(1.0989011),
                                           -log(0.8440000),
                                           -log(1.0730000),
                                           -log(1.453),
                                           log(1.3089005),
                                           log(1.1848341),
                                           -log(1.6140000),
                                           -log(1.716),
                                           log(0.9727626),
                                           log(0.9319664),
                                           log(0.6195787),
                                           -log(1.354),
                                           log(0.7575758),
                                           log(0.6882312),
                                           log(0.5827506),
                                           log(0.7385524)
                                           ), nrow=20, byrow=TRUE)

currency.graph &lt;- add_edges(initial.graph,t(graph.edges),weight=graph.weights)
plot(currency.graph)

arbitrage.actions &lt;- distances(currency.graph, v=V(currency.graph), to=V(currency.graph), algorithm=&quot;bellman

</code></pre>
<figure data-type="image" tabindex="3"><img src="https://yshuai99.github.io/post-images/1645714320207.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pairs Trading]]></title>
        <id>https://yshuai99.github.io/post/pairs-trading-in-progress_/</id>
        <link href="https://yshuai99.github.io/post/pairs-trading-in-progress_/">
        </link>
        <updated>2021-12-30T04:16:54.000Z</updated>
        <summary type="html"><![CDATA[<p>Here is the R code and example for the pairs trading.</p>
]]></summary>
        <content type="html"><![CDATA[<p>Here is the R code and example for the pairs trading.</p>
<!-- more -->
<h2 id="code">Code</h2>
<pre><code class="language-R">library(egcm)
library(quantmod)
library(PerformanceAnalytics)

s &lt;- yegcm(&quot;KO&quot;, &quot;PEP&quot;, start=&quot;1972-01-01&quot;, end=&quot;2000-01-01&quot;)

plot(s)

getSymbols(&quot;KO&quot;,from=&quot;1972-06-01&quot;, to=&quot;2000-01-01&quot;)
getSymbols(&quot;PEP&quot;,from=&quot;1972-06-01&quot;, to=&quot;2000-01-01&quot;)

train_start &lt;- &quot;1972-06-01&quot;
train_end &lt;- &quot;1994-01-01&quot;

test_start &lt;- &quot;1994-01-02&quot;
test_end &lt;- &quot;2000-01-01&quot;

train_ko &lt;- train_ko$KO.Adjusted

train_ko &lt;- KO[paste0(train_start, '/', train_end)]
train_pep &lt;- PEP[paste0(train_start, '/', train_end)]

test_ko &lt;- KO[paste0(test_start, '/', test_end)]
test_pep &lt;- PEP[paste0(test_start, '/', test_end)]

train_ko &lt;- train_ko$KO.Adjusted
train_pep &lt;- train_pep$PEP.Adjusted

test_ko &lt;- test_ko$KO.Adjusted
test_pep &lt;- test_pep$PEP.Adjusted

lm &lt;- lm(train_ko~train_pep)
summary(lm)

#KO=-0.88215 + 0.574203*PEP + residuals. Standard deviation=0.3543
#spread=KO - 0.574203*PEP

beta &lt;- 0.574203
std &lt;- 0.3543

spread = train_ko-beta*train_pep

upper_bound &lt;- mean(spread)-beta
lower_bound &lt;- mean(spread)+beta

buy_signals &lt;- ifelse(spread &lt;= upper_bound, 1, 0)
sell_signals &lt;- ifelse(spread &gt;= lower_bound, 1, 0)

pair_strategy &lt;- cbind(spread, buy_signals,sell_signals)
colnames(pair_strategy) &lt;- c(&quot;spread&quot;, &quot;buy_signals&quot;,&quot;sell_signals&quot;)

plot(spread)

#For signals like 1,1,1,1,1,1,0, only trade at first signal.

position &lt;- 0
pair_strategy$position &lt;- position

pair_strategy$return = diff(log(pair_strategy$spread))

plot(train_pair_strategy$spread, main = &quot; &quot;,
     cex.main = 0.8,
     cex.lab = 0.8,
     cex.axis = 0.8)
abline(h = threshold_1, lty = 2)
abline(h = threshold_2, lty = 2)

point_type &lt;- rep(NA, nrow(train_pair_strategy))
buy_index &lt;- which(train_pair_strategy$buy_signals == 1)
sell_index &lt;- which(train_pair_strategy$sell_signals == 1)

point_type[buy_index] &lt;- 21
point_type[sell_index] &lt;- 24
points(train_pair_strategy$spread, pch = point_type)

for(i in 1:length(buy_signals)){
  if(pair_strategy$buy_signals[i]==1 &amp;&amp; pair_strategy$sell_signals[i]==0 ){
    pair_strategy$position[i] &lt;- 1
    pair_strategy$position[i+1] &lt;- 1
  }
  if(pair_strategy$buy_signals[i]==0 &amp;&amp; pair_strategy$sell_signals[i]==0 &amp;&amp; pair_strategy$position[i]==1 ){
    pair_strategy$position[i+1] &lt;- 1
  }
  if(pair_strategy$buy_signals[i]==0 &amp;&amp; pair_strategy$sell_signals[i]==1){
    pair_strategy$position[i] &lt;- 0
  }
}



train_return &lt;- na.omit(train_pair_strategy$return[which(train_pair_strategy$position == 1)])
tail(cumsum(train_return$return),1)
SharpeRatio(train_return$return)


test_spread = test_ko-beta*test_pep
test_buy_signals &lt;- ifelse(test_spread &lt;= threshold_1, 1, 0)
test_sell_signals &lt;- ifelse(test_spread &gt;= threshold_2, 1, 0)

test_pair_strategy &lt;- cbind(test_spread, test_buy_signals,test_sell_signals)
colnames(test_pair_strategy) &lt;- c(&quot;spread&quot;, &quot;buy_signals&quot;,&quot;sell_signals&quot;)

plot(test_pair_strategy$spread, main = &quot; &quot;,
     cex.main = 0.8,
     cex.lab = 0.8,
     cex.axis = 0.8)
abline(h = threshold_1, lty = 2)
abline(h = threshold_2, lty = 2)

point_type &lt;- rep(NA, nrow(test_pair_strategy))
buy_index &lt;- which(test_pair_strategy$buy_signals == 1)
sell_index &lt;- which(test_pair_strategy$sell_signals == 1)

point_type[buy_index] &lt;- 21
point_type[sell_index] &lt;- 24
points(test_pair_strategy$spread, pch = point_type)


test_pair_strategy$return = diff(log(-test_pair_strategy$spread))

position &lt;- 0
test_pair_strategy$position &lt;- position

for(i in 1:(length(test_buy_signals)-1)){
  if(test_pair_strategy$buy_signals[i]==1 &amp;&amp; test_pair_strategy$sell_signals[i]==0 ){
    test_pair_strategy$position[i] &lt;- 1
    test_pair_strategy$position[i+1] &lt;- 1
  }
  if(test_pair_strategy$buy_signals[i]==0 &amp;&amp; test_pair_strategy$sell_signals[i]==0 &amp;&amp; test_pair_strategy$position[i]==1 ){
    test_pair_strategy$position[i+1] &lt;- 1
  }
  if(test_pair_strategy$buy_signals[i]==0 &amp;&amp; test_pair_strategy$sell_signals[i]==1){
    test_pair_strategy$position[i] &lt;- 0
  }
}

test_return &lt;- na.omit(test_pair_strategy$return[which(test_pair_strategy$position == 1)])

tail(cumsum(test_return$return),1)
SharpeRatio(test_return$return)

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[The performance of macroeconomic factors timing in Chinese stock market ]]></title>
        <id>https://yshuai99.github.io/post/the-performance-of-macroeconomic-factors-timing-in-chinese-stock-market-/</id>
        <link href="https://yshuai99.github.io/post/the-performance-of-macroeconomic-factors-timing-in-chinese-stock-market-/">
        </link>
        <updated>2021-12-07T10:54:41.000Z</updated>
        <summary type="html"><![CDATA[<p>This blog analysis the performance of 9 macroeconomic factors timing strategy in Chinese stock market</p>
]]></summary>
        <content type="html"><![CDATA[<p>This blog analysis the performance of 9 macroeconomic factors timing strategy in Chinese stock market</p>
<!-- more -->
<h1 id="key-points">Key points</h1>
<ul>
<li>I analyze the macroeconomic factors timing strategy in Chinese stock market and find that the single macroeconomic factor is not a good index to long/short Chinese stock market index. However, the 9 macroeconomic factors together is a good indicator to the Chinese stock maket.</li>
<li>The 9 macroeconomic factors are from 5 main aspects of macroeconomic (Economic growth, Interest rate, Credit, Inflation and Exchange rate) and the factor timing strategy is based on the technological analysis tools: Bollinger Bands, Moving averages, etc.</li>
</ul>
<p>The idea of this blog is inspired by the Yujie Chu, the senior manager of Baofu Internet Technology. The data and python API was provided by Joinquant platform (joinquant.com).</p>
<h1 id="macroeconomic-factors">Macroeconomic factors</h1>
<h2 id="pmi">PMI</h2>
<p>The Purchasing Managers' Index (PMI) is an index of the prevailing direction of economic trends in the manufacturing and service sectors. Its purpose is to provide information about current and future business conditions to company decision makers, analysts, and investors. The PMI is based on a monthly survey sent to senior executives and it is complied and released monthly.</p>
<p>The headline PMI is a number from 0 to 100. A PMI above 50 represents an expansion when compared with the previous month. A PMI reading under 50 represents a contraction, and a reading at 50 indicates no change. The further away from 50 indicating the greater the level of change.</p>
<blockquote>
<p>Investors can also use the PMI to their advantage because it is a leading indicator of economic conditions. The direction of the trend in the PMI tends to precede changes in the trend in major estimates of economic activity and output, such as the GDP, Industrial Production, and Employment. Paying attention to the value and movements in the PMI can yield profitable foresight into developing trends in the overall economy.  (investopedia.com)</p>
</blockquote>
<h2 id="shibor">SHIBOR</h2>
<p>The Shanghai Interbank Offered Rate is a  wholesale interest rate calculated by arithmetically averaging all the interbank RMB lending rates offered by the price quotation group of banks with a high credit rating. In this article, the SHIBOR with 1-month maturity is used, as it is reflect the pricing of middle and short term interest rate pricing and it has lower noise than the overnight interbank RMB lending rates.</p>
<h2 id="yield-spread">Yield Spread</h2>
<p>In this report, the yield spread is the difference of yield between 10 years government bonds and 1 year. It is the result of multiple of factors, such as fed target rate, real GDP growth, inflation and institutional demand. Usually it have a upwarding slope, meaning that the market hold positive expectation towards the economy situation. However, the yield curve would have a flat or even inverted curve if the market holds pessimistic expectations.</p>
<p>Usually the inverted yield curve is surronded with higher interest rate and tight credit policy, which is a negative signal for stock market.</p>
<h2 id="credit">Credit</h2>
<p>Here the economic factors is the difference of yield between 1-month AAA corporate bond and 1-month government bonds. This spread also reflects the expectation of economic. It will increase during economic contraction period as investors would rather choose higher credit bonds such as government bonds. While during expansion time, investors hold optimistic towards the market and choose the bonds with lower credit to get higher return.</p>
<h2 id="m1-m2">M1-M2</h2>
<p>In this blog this factor would be the difference of increase rate between M1 and M2.</p>
<blockquote></blockquote>
<ul>
<li>M0: The sum of Currency in Circulation</li>
<li>M1: The sum of Currency with the Public, Demand Deposits with the Banking System</li>
<li>M2: The sum of Currency with the Public, Current Deposits with the Banking System, Savings Deposits with the Banking System, Certificates of Deposits issued by Banks, Term Deposits of residents with a contractual maturity up to and including one year with the Banking System<br>
(https://www.clearias.com/monetary-aggregates/)</li>
</ul>
<h2 id="aggregate-financing-to-the-real-economy">Aggregate Financing to the Real Economy</h2>
<p>Aggregate Financing to the Real Economy refers to the aggregate volume of funds provided by China’s domestic financial system to the private sector of the real economy within a given timeframe.</p>
<p>The Chinese government employs it as a liquidity measurement tool to abet the formation of monetary policy.</p>
<h2 id="reserve-ratio">Reserve Ratio</h2>
<p>The reserve ratio is the portion of reservable liabilities that commercial banks must hold onto, rather than lend out or invest. This is a requirement determined by the country's central bank. The minimum amount of reserves that a bank must hold on to is referred to as the reserve requirement, and is sometimes used synonymously with the reserve ratio.</p>
<p>The relationship of reserve ratio with stock market is unsatble, but generally speaking the decreasing of reserve ratio is a positive sign for stock market.</p>
<h2 id="usdcnh-spot-exchange-rate">USDCNH: Spot Exchange Rate</h2>
<p>For emerging market, the expectation of spot rate reflects the stability of stock market and econoic condition.</p>
<h2 id="ppi-cpi">PPI-CPI</h2>
<p>CPI: Consumer Price Index, is a measure that examines the weighted average of prices of a basket of consumer goods and services, such as transportation, food, and medical care.<br>
PPI: Producer Price Index, measures the average change over time in the selling prices received by domestic producers for their output. The prices included in the PPI are from the first commercial transaction for many products and some services.</p>
<p>PPI-CPI reflect the difference of industrial goods and consumer goods.</p>
<h1 id="analysis-method">Analysis method</h1>
<h2 id="bollinger-band">Bollinger Band</h2>
<p>Bollinger Band tells you:</p>
<ul>
<li>the overbuy and oversell</li>
<li>trend<br>
​<br>
The calculation of Bollinger Band would be:</li>
</ul>
<p>BOLU=MA(TP,n)+m∗σ[TP,n]<br>
BOLD=MA(TP,n)−m∗σ[TP,n]<br>
where:<br>
BOLU=Upper Bollinger Band<br>
BOLD=Lower Bollinger Band<br>
MA=Moving average<br>
TP (typical price)=(High+Low+Close)÷3<br>
n=Number of days in smoothing period (typically 20)<br>
m=Number of standard deviations (typically 2)<br>
σ[TP,n]=Standard Deviation over last n periods of TP</p>
<h2 id="backtest">Backtest</h2>
<pre><code class="language-python">class backtest_result():
    def __init__(self,data):
        self.data = data
        self.total_returns = data.iloc[-1]-1
        self.annualized_returns = data.iloc[-1]**(12./len(data))-1
        self.annualized_volatility = data.pct_change().std()*(12.**0.5)
    def Max_Drawback(self):
        net_value=self.data
        max_value=0
        df_tmp=pd.DataFrame(net_value)
        df_tmp.columns=['value']
        for j in range(0,len(net_value),1):
            max_value=max(max_value,df_tmp.ix[j,'value'])
            df_tmp.ix[j,'drawback']=1-df_tmp.ix[j,'value']/max_value
            drawback=df_tmp['drawback'].max()
        return drawback
    def Sharpe(self):
        net_value=self.data
        bench_pct=0.03
        df_tmp=pd.DataFrame(net_value)
        df_tmp.columns=['value']
        df_tmp['pct']=df_tmp['value'].pct_change()
        annual_pct = df_tmp.ix[-1,'value']**(12./len(df_tmp))-1
        sharpe = (annual_pct-bench_pct)/(df_tmp['pct'].std()*12**0.5)
        return sharpe
    def Calmar(self):
        Clamar = self.annualized_returns/self.Max_Drawback()
        return Calmar
</code></pre>
<p>​</p>
<h1 id="code">Code</h1>
<pre><code class="language-python">from jqdata import *
import numpy as np
import pandas as pd
import datetime as dt
from six import StringIO
from dateutil.parser import parse
import cPickle as pickle
import seaborn as sns
import matplotlib as mpl
import os
import statsmodels.api as sm
import scipy
import talib as tl


mpl.rcParams['font.family']='serif'
mpl.rcParams['axes.unicode_minus']=False # 处理负号

load_data={}

path = '/home/jquser/Macro'

class backtest_result():
    def __init__(self,data):
        self.data = data
        self.total_returns = data.iloc[-1]-1
        self.annualized_returns = data.iloc[-1]**(12./len(data))-1
        self.annualized_volatility = data.pct_change().std()*(12.**0.5)
    def Max_Drawback(self):
        net_value=self.data
        max_value=0
        df_tmp=pd.DataFrame(net_value)
        df_tmp.columns=['value']
        for j in range(0,len(net_value),1):
            max_value=max(max_value,df_tmp.ix[j,'value'])
            df_tmp.ix[j,'drawback']=1-df_tmp.ix[j,'value']/max_value
            drawback=df_tmp['drawback'].max()
        return drawback
    def Sharpe(self):
        net_value=self.data
        bench_pct=0.03
        df_tmp=pd.DataFrame(net_value)
        df_tmp.columns=['value']
        df_tmp['pct']=df_tmp['value'].pct_change()
        annual_pct = df_tmp.ix[-1,'value']**(12./len(df_tmp))-1
        sharpe = (annual_pct-bench_pct)/(df_tmp['pct'].std()*12**0.5)
        return sharpe
    def Calmar(self):
        clamar = self.annualized_returns/self.Max_Drawback()
        return clamar

#PMI
body=read_file(path+'/PMI组合.xls')
df_boom=pd.read_excel(StringIO(body))
print df_boom.columns
col =u'PMI'
df_boom=df_boom.set_index(u'日期')
df_boom.plot(figsize=(15,6),title='PMI')

n=3
df_boom['position']=(pd.rolling_mean(df_boom[col],n).shift(1)&gt;pd.rolling_mean(df_boom[col],n).shift(2))*1.
prices = get_price('000300.XSHG',start_date='2006-01-01',end_date='2018-11-30',fields='close')['close']
prices_M = prices.resample('M',how='last')
rate_riskfree = 0
df_pct=pd.DataFrame()
df_pct['pct']=prices_M.pct_change()
df_pct['position']=df_boom['position']
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()

df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='PMI择时')


#SHIBOR
body=read_file(path+'/SHIBOR数据.xls')
df_interest=pd.read_excel(StringIO(body))
col = u'SHIBOR:1个月'
df_interest=df_interest.set_index(u'日期')
df_interest.iloc[:,1:2].plot(figsize=(15,6),title='SHIBOR')

df_interest=df_interest[[col]]
upperband,middleband,lowerband = (tl.BBANDS(df_interest[col].values, timeperiod=12, nbdevup=1.8, nbdevdn=1.8))
# print df_1

df_interest['BBAND_upper']=upperband
df_interest['BBAND_middle']=middleband
df_interest['BBAND_lower']=lowerband

pre_position = 0
for date in df_interest.index:
    if df_interest.loc[date,col]&gt;df_interest.loc[date,'BBAND_middle']:
        df_interest.loc[date,'position']=0
    elif df_interest.loc[date,col]&lt;df_interest.loc[date,'BBAND_lower']:
        df_interest.loc[date,'position']=1.0
    else:
        df_interest.loc[date,'position']=pre_position
    pre_position=df_interest.loc[date,'position']
df_interest['position']=df_interest['position'].shift(1)

df_pct=pd.DataFrame()
prices = get_price('000300.XSHG',start_date='2005-01-01',end_date='2018-11-30',fields='close')['close']
df_pct['pct']=prices.pct_change()

rate_riskfree = 0
df_pct = pd.concat([df_pct,df_interest],axis=1)['2006-01-01':'2018-11-30'].dropna()
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='SHIBOR:1M择时')

#Yield

body=read_file(path+'/国债到期收益率.xls')
df_tbonds=pd.read_excel(StringIO(body))
df_tbonds.set_index(u'日期',inplace=True)
df_tbonds=df_tbonds.fillna(method='ffill')
term_spread_tbonds = df_tbonds[u'中债国债到期收益率:10年']-df_tbonds[u'中债国债到期收益率:1个月']
term_spread_tbonds_diff = term_spread_tbonds.diff(21)
term_spread_tbonds=pd.rolling_mean(term_spread_tbonds,1)
term_spread_tbonds.plot(figsize=(15,6),title='10年-1年国债期限利差')

df_termspread=pd.DataFrame()
col='termspread'
df_termspread=term_spread_tbonds.to_frame('termspread')
upperband,middleband,lowerband = (tl.BBANDS(df_termspread[col].values, timeperiod=25, nbdevup=1.8, nbdevdn=1.8))

df_termspread['BBAND_upper']=upperband
df_termspread['BBAND_middle']=middleband
df_termspread['BBAND_lower']=lowerband

df_termspread.head()
pre_position = 0
for date in df_termspread.index:
    if df_termspread.loc[date,col]&lt;df_termspread.loc[date,'BBAND_middle']:
        df_termspread.loc[date,'position']=0
    elif df_termspread.loc[date,col]&gt;df_termspread.loc[date,'BBAND_upper']:
        df_termspread.loc[date,'position']=1.0
    else:
        df_termspread.loc[date,'position']=pre_position
    pre_position=df_termspread.loc[date,'position']
df_termspread['position']=df_termspread['position'].shift(1)
df_termspread.head().append(df_termspread.tail())

df_pct=pd.DataFrame()
prices = get_price('000300.XSHG',start_date='2005-01-01',end_date='2018-11-30',fields='close')['close']
df_pct['pct']=prices.pct_change()

rate_riskfree = 0
df_pct = pd.concat([df_pct,df_termspread],axis=1)['2007-01-01':'2018-11-30'].dropna()
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='国债期限利差择时')

# Credit

body=read_file(path+'/企业债到期收益率(AAA).xls')
df_cbonds=pd.read_excel(StringIO(body))
df_cbonds.set_index(u'日期',inplace=True)
df_cbonds=df_cbonds.fillna(method='ffill')
credit_spread=df_cbonds[u'中债企业债到期收益率(AAA):1个月']-df_tbonds[u'中债国债到期收益率:1个月']
credit_spread=pd.rolling_mean(credit_spread,1)
credit_spread['2006-01-01':].plot(figsize=(15,6),title='AAA企业债信用利差:1个月')

df_creditspread=pd.DataFrame()
col='creditspread'
df_creditspread=credit_spread.to_frame('creditspread')
upperband,middleband,lowerband = (tl.BBANDS(df_creditspread[col].values, timeperiod=25, nbdevup=1.8, nbdevdn=1.8))

df_creditspread['BBAND_upper']=upperband
df_creditspread['BBAND_middle']=middleband
df_creditspread['BBAND_lower']=lowerband
pre_position = 0
for date in df_creditspread.index:
    if df_creditspread.loc[date,col]&gt;df_creditspread.loc[date,'BBAND_middle']:
        df_creditspread.loc[date,'position']=0
    elif df_creditspread.loc[date,col]&lt;df_creditspread.loc[date,'BBAND_lower']:
        df_creditspread.loc[date,'position']=1.0
    else:
        df_creditspread.loc[date,'position']=pre_position
    pre_position=df_creditspread.loc[date,'position']
df_creditspread['position']=df_creditspread['position'].shift(1)

df_pct=pd.DataFrame()
prices = get_price('000300.XSHG',start_date='2005-01-01',end_date='2018-11-30',fields='close')['close']
df_pct['pct']=prices.pct_change()

rate_riskfree =0
df_pct = pd.concat([df_pct,df_creditspread],axis=1)['2007-01-01':'2018-11-30'].dropna()
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='信用利差择时')

#M1-M2

body=read_file(path+'/信贷.xls')
df_credit_loan_1=pd.read_excel(StringIO(body))
df_credit_loan_1=df_credit_loan_1.set_index(u'日期')
print df_credit_loan_1.columns
col = u'社会融资规模:当月值'
col_1 = u'M1:同比'
col_2 = u'M2:同比'
# col = col_1
col = u'M1-M2'
df_credit_loan_1[u'M1-M2'] = df_credit_loan_1[u'M1:同比']-df_credit_loan_1[u'M2:同比']
n=3
df_credit_loan_1.iloc[:,1:].plot(figsize=(15,6),title='M1,M2及剪刀差')


df_credit_loan_1['position']=pd.rolling_mean(df_credit_loan_1[col],n).shift(2)&gt;pd.rolling_mean(df_credit_loan_1[col],n).shift(3)
prices = get_price('000300.XSHG',start_date='2005-01-01',end_date='2018-11-30',fields='close')['close']
prices_M = prices.resample('M',how='last')

rate_riskfree = 0

df_pct=pd.DataFrame()
df_pct['pct']=prices_M.pct_change()
df_pct['position']=df_credit_loan_1['position']
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='M1,M2剪刀差择时')

#Financing

body=read_file(path+'/信贷.xls')
df_credit_loan_2=pd.read_excel(StringIO(body))
df_credit_loan_2=df_credit_loan_2.set_index(u'日期')
print df_credit_loan_2.columns
col = u'社会融资规模:当月值'
col_1 = u'M1:同比'
col_2 = u'M2:同比'
n=3
pd.rolling_mean(df_credit_loan_2.iloc[:,:1],1)['2005-01-01':].plot(figsize=(15,6),title='社融规模：当月值')

df_credit_loan_2['position']=pd.rolling_mean(df_credit_loan_2[col],n).shift(2)&gt;pd.rolling_mean(df_credit_loan_2[col],n).shift(3)
prices = get_price('000300.XSHG',start_date='2005-01-01',end_date='2018-12-07',fields='close')['close']
prices_M = prices.resample('M',how='last')

rate_riskfree = 0

df_pct=pd.DataFrame()
df_pct['pct']=prices_M.pct_change()
df_pct['position']=df_credit_loan_2['position']
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='社融择时')

# Reserve Ratio
body=read_file(path+'/存款准备金率-大型存款类机构.xls')
df_reserves=pd.read_excel(StringIO(body))
df_reserves = df_reserves.set_index(u'日期')
df_reserves
col=u'人民币存款准备金率:大型存款类金融机构'
df_pct=pd.DataFrame()
prices = get_price('000300.XSHG',start_date='2006-01-01',end_date='2018-11-30',fields='close')['close']
prices_M = prices.resample('M',how='last')
df_pct['pct']=prices.pct_change()
df_pct
rate_riskfree=0

df_reserves=df_reserves.reindex(prices.index).fillna(method='ffill')
fig = plt.figure(figsize=(15,6))
ax1=fig.add_subplot(111)
ax1.plot(df_reserves[col],'y-',linewidth=2,label='大型机构存款准备金率')
ax1.legend(loc=2,fontsize=12)
ax2=ax1.twinx()
ax2.plot(prices,'b-',linewidth=2,label='沪深300指数')
ax2.legend(loc=1,fontsize=12)
ax2.grid(False)
plt.show()

pre_position=0
delay_days=120
for i in range(delay_days,len(df_reserves)):
    pre_index = df_reserves.index[i-delay_days]
    index = df_reserves.index[i]
#     print df_reserves.loc[index,col]
    if df_reserves.loc[index,col]&lt;df_reserves.loc[pre_index,col]:
        df_reserves.loc[index,'position']=1
    elif df_reserves.loc[index,col]&gt;df_reserves.loc[pre_index,col]:
        df_reserves.loc[index,'position']=0.
    else:
        df_reserves.loc[index,'position']=0.
    pre_position = df_reserves.loc[index,'position']
df_pct['position'] = df_reserves['position']
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='存款准备金择时')

#USDCHN

body=read_file(path+'/离岸汇率数据.xls')
df_exchange_rate=pd.read_excel(StringIO(body))
col = u'USDCNH:即期汇率'
df_exchange_rate=df_exchange_rate.set_index(u'日期')
df_exchange_rate.plot(figsize=(15,6),title='USDCNH:即期汇率')

upperband,middleband,lowerband = (tl.BBANDS(df_exchange_rate[col].values, timeperiod=25, nbdevup=1.8, nbdevdn=1.8))
df_exchange_rate['BBAND_upper']=upperband
df_exchange_rate['BBAND_middle']=middleband
df_exchange_rate['BBAND_lower']=lowerband
df_exchange_rate.head()
pre_position = 0
for date in df_exchange_rate.index:
    if df_exchange_rate.loc[date,col]&gt;df_exchange_rate.loc[date,'BBAND_middle']:
        df_exchange_rate.loc[date,'position']=0
    elif df_exchange_rate.loc[date,col]&lt;df_exchange_rate.loc[date,'BBAND_lower']:
        df_exchange_rate.loc[date,'position']=1.0
    else:
        df_exchange_rate.loc[date,'position']=pre_position
    pre_position=df_exchange_rate.loc[date,'position']
df_exchange_rate['position']=df_exchange_rate['position'].shift(1)
df_exchange_rate.head().append(df_exchange_rate.tail())

df_pct=pd.DataFrame()
prices = get_price('000300.XSHG',start_date='2005-01-01',end_date='2018-12-07',fields='close')['close']
df_pct['pct']=prices.pct_change()
df_pct = pd.concat([df_pct,df_exchange_rate],axis=1)['2007-01-01':'2018-11-30'].dropna()
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='USDCNH:即期汇率择时')

#PPI-CPI
body=read_file(path+'/CPI与PPI.xls')
df_inflation=pd.read_excel(StringIO(body))
print df_inflation.columns
col_0 =u'CPI:当月同比'
col_1 =u'PPI:全部工业品:当月同比'
df_inflation=df_inflation.set_index(u'日期')['2005-01-31':]
col_2 = u'PPI-CPI'
df_inflation[col_2] = -df_inflation[u'CPI:当月同比']+df_inflation[u'PPI:全部工业品:当月同比']
df_inflation[[col_0,col_1,col_2]].plot(figsize=(15,6))

def good_cpi(x):
    if x&lt;0:
        y=0.
    elif x&lt;5.:
        y=1.
    else:
        y=0
    return y
    
n=3
df_inflation['position']=(pd.rolling_mean(df_inflation[col_2],n).shift(2)&lt;pd.rolling_mean(df_inflation[col_2],n).shift(3))*\
    (pd.rolling_mean(df_inflation[col_0],n).apply(good_cpi).shift(2))

prices = get_price('000300.XSHG',start_date='2006-01-01',end_date='2018-11-30',fields='close')['close']
prices_M = prices.resample('M',how='last')
rate_riskfree = 0#(1+1.25e-4)**20.0-1
df_pct=pd.DataFrame()
df_pct['pct']=prices_M.pct_change()
df_pct['position']=df_inflation['position']
df_pct['net_value'] =(df_pct['pct']+1).cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1).cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='PPI,CPI剪刀差择时')

</code></pre>
<h1 id="combination-of-factors">Combination of factors</h1>
<pre><code class="language-python">def dateRange(beginDate, endDate):
    dates = []
    dt=beginDate
    date = beginDate
    while date &lt;= endDate:
        dates.append(date)
        dt = dt + datetime.timedelta(1)
        date = dt
    return dates
date_list = dateRange(prices_M.index[0],prices_M.index[-1])

df_interest_M = df_interest['position'].reindex(date_list).fillna(method='ffill').reindex(prices_M.index).shift(1)
df_termspread_M = df_termspread['position'].reindex(date_list).fillna(method='ffill').reindex(prices_M.index).shift(1)
df_creditspread_M = df_creditspread['position'].reindex(date_list).fillna(method='ffill').reindex(prices_M.index).shift(1)
df_monetray = ((df_interest_M*1 + df_termspread_M*1 + df_creditspread_M*1)/3.)*1
df_forex = (df_exchange_rate['position'].reindex(date_list).fillna(method='ffill').reindex(prices_M.index).shift(1))
df_credit_loan = ((df_credit_loan_1['position']*1+df_credit_loan_2['position']*1)/2.)*1

df_month=pd.concat([df_monetray,df_forex,df_credit_loan,\
                  df_boom['position'],df_inflation['position']],axis=1)
factor_columns = ['monetary','forex','credit','boom','inflation']
df_month.columns = factor_columns

#Equal weight
weight_f=([1,1,1,1,1])
timing_count=((df_month[factor_columns]&gt;=0)*weight_f).sum(axis=1)

df_month['tot_pos'] = ((df_month[factor_columns]*weight_f).sum(axis=1)/timing_count&gt;0.55)*0.5+\
    ((df_month[factor_columns]*weight_f).sum(axis=1)/timing_count&gt;0.45)*0.5
prices = get_price('000300.XSHG',start_date='2006-01-01',end_date='2018-11-30',fields='close')['close']
prices_M = prices.resample('M',how='last')
rate_riskfree = 0
df_pct=pd.DataFrame()
start_date='2007-01-01'
df_pct['pct']=prices_M.pct_change()[start_date:]
df_pct['position']=df_month['tot_pos']
df_pct['net_value'] =(df_pct['pct']+1)[start_date:].cumprod()
df_pct['net_value_timing'] = (df_pct['pct']*df_pct['position']+rate_riskfree*(1-df_pct['position'])+1)[start_date:].cumprod()
df_pct[['net_value','net_value_timing']].plot(figsize=(15,6),title='宏观指标综合择时(信贷系数=1)')
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://yshuai99.github.io/post-images/1645753122870.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effectiveness of Some Fundamental Factors in China Stock Market]]></title>
        <id>https://yshuai99.github.io/post/fundamental-factors/</id>
        <link href="https://yshuai99.github.io/post/fundamental-factors/">
        </link>
        <updated>2021-06-22T19:57:25.000Z</updated>
        <summary type="html"><![CDATA[<p>I analyzed the collinearity, exposure and IC of 8 fundamental factors in China stock market.</p>
]]></summary>
        <content type="html"><![CDATA[<p>I analyzed the collinearity, exposure and IC of 8 fundamental factors in China stock market.</p>
<!-- more -->
<pre><code class="language-python">from jqdata import *
import datetime
import pandas as pd
import numpy as np
from six import StringIO
import warnings
import time
import pickle
from jqfactor import winsorize_med
from jqfactor import neutralize
from jqfactor import standardlize
import statsmodels.api as sm
warnings.filterwarnings(&quot;ignore&quot;)
matplotlib.rcParams['axes.unicode_minus']=False
</code></pre>
<pre><code class="language-python">import matplotlib.pyplot as plt

Fields = ['turnover_ratio', 'pe_ratio', 'market_cap', 'capitalization', 'eps', 'roe', 'inc_net_profit_year_on_year', 'volume']
def getExplore(index):
    if index == 'SH50':
        index = '000016.XSHG'
    if index == 'HS300':
        index = '000300.XSHG'
    if index == 'ZZ500':
        index = '000905.XSHG'
    explore = pd.DataFrame(index = TradeDate)
    for i in Fields:#对于每一个单独的因子
        tempExplore = []
        for date in TradeDate:
            stockList = get_index_stocks(index, date)#获取指定日期的股票列表
            temp = factorData[date][[i]]#对于每一支股票和单独的因子，在每一个交易日下
            temp = temp.sort([i],ascending = False)#将每日因子从大到小排列
            temp['rank'] = range(len(temp)+1, 1, -1)#给排列好的因子加上序号
            #获取因子在某一交易日的暴露度
            tempExplore.append((temp.loc[stockList,'rank'].mean() - len(temp) / 2) / len(temp))
        explore[i] = tempExplore
    return explore
result_SH50 = []
result_HS300 = []
result_ZZ500 = []
explore1 = getExplore('SH50')
explore2 = getExplore('HS300')
explore3 = getExplore('ZZ500')
for i in Fields:#获取因子的平均暴露度
    result_SH50.append(explore1[i].mean())
    result_HS300.append(explore2[i].mean())
    result_ZZ500.append(explore3[i].mean())
</code></pre>
<pre><code class="language-python">Year= ['2014', '2015', '2016', '2017', '2018']
Fields = ['turnover_ratio', 'pe_ratio', 'market_cap', 'capitalization', 'eps', 'roe', 'inc_net_profit_year_on_year', 'volume']
total1 = pd.DataFrame()
total2 = pd.DataFrame()
total3 = pd.DataFrame()
for i in range(len(Year)):#获取因子的年度平均暴露度
    total1[Year[i]] = explore1.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total2[Year[i]] = explore2.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total3[Year[i]] = explore3.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
x = np.array(range(len(Year)))
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total1.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;SH50&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
x = np.array(range(len(Year)))
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total2.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;HS300&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
x = np.array(range(len(Year)))
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total3.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;ZZ500&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
</code></pre>
<pre><code class="language-python">def getCorr(index):#计算相关性
    if index == 'SH50':
        index = '000016.XSHG'
    if index == 'HS300':
        index = '000300.XSHG'
    if index == 'ZZ500':
        index = '000905.XSHG'
    corr = {}
    for date in TradeDate:
        stockList = get_index_stocks(index, date)
        temp = factorData[date].loc[stockList,:]
        corr[date] = temp.corr()
    corr = pd.Panel.from_dict(corr)
    return corr
corr_SH50 = getCorr('SH50')
corr_HS300 = getCorr('HS300')
corr_ZZ500 = getCorr('ZZ500')

import seaborn as sns#计算相关性标准差，由corr_.mean实现
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(corr_SH50.mean(axis = 0), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;SH50&quot;, fontsize=21)
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(corr_HS300.mean(axis = 0), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;HS300&quot;, fontsize=21)
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(corr_ZZ500.mean(axis = 0), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;ZZ500&quot;, fontsize=21)
fig.show()

fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(corr_SH50.std(axis = 0), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;SH50&quot;, fontsize=21)
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(corr_HS300.std(axis = 0), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;HS300&quot;, fontsize=21)
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(corr_ZZ500.std(axis = 0), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;ZZ500&quot;, fontsize=21)
fig.show()

fig = plt.figure(figsize=(15,6))#计算相关强度
ax = fig.add_subplot(111)
sns.heatmap((corr_SH50.mean(axis = 0) / corr_SH50.std(axis = 0)).astype(int), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;SH50&quot;, fontsize=21)
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap((corr_HS300.mean(axis = 0) / corr_HS300.std(axis = 0)).astype(int), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;HS300&quot;, fontsize=21)
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap((corr_ZZ500.mean(axis = 0) / corr_ZZ500.std(axis = 0)).astype(int), annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;ZZ500&quot;, fontsize=21)
fig.show()


</code></pre>
<pre><code class="language-python">import scipy.stats as st
def factor_IC_analysis(factorData, index):  
    if index == 'SH50':
        index = '000016.XSHG'
    if index == 'HS300':
        index = '000300.XSHG'
    if index == 'ZZ500':
        index = '000905.XSHG'
    if index == 'A':
        index = None
    IC = []
    for date in TradeDate[:-1]:
        if index:
            #取股票池
            stockList = get_index_stocks(index, date)
        else:
            stockList = list(factorData[date].index)
        #获取横截面收益率
        df_close=get_price(stockList, date, TradeDate[TradeDate.index(date)+1], 'daily', ['close'])
        if df_close.empty:
            continue
        #获取收益率的变化比率
        df_pchg=df_close['close'].iloc[-1,:]/df_close['close'].iloc[0,:]-1
        R_T = pd.DataFrame()
        R_T['pchg']=df_pchg
        IC_Field = []
        for i in Fields:
            #获取因子数据
            factor_data = factorData[date].loc[stockList, i]
            R_T['factor'] = factor_data
            R_T = R_T.dropna()
            IC_Field.append(st.pearsonr(R_T.pchg.rank(), R_T['factor'].rank())[0])
        IC.append(IC_Field)
    result = pd.DataFrame(index = TradeDate[:-1], columns = Fields, data = IC)
    result = result.dropna(how = 'all')
    return result
IC_SH50 = factor_IC_analysis(factorData, 'SH50')
IC_HS300 = factor_IC_analysis(factorData, 'HS300')
IC_ZZ500 = factor_IC_analysis(factorData, 'ZZ500')
IC_A = factor_IC_analysis(factorData, 'A')

temp = pd.DataFrame()
temp['A'] = IC_A.mean()
temp['SH50'] = IC_SH50.mean()
temp['HS300'] = IC_HS300.mean()
temp['ZZ500'] = IC_ZZ500.mean()
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(temp, annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;IC Mean&quot;, fontsize=21)
fig.show()

#IC波动性计算
Year= ['2014', '2015', '2016', '2017', '2018']
Fields = ['turnover_ratio', 'pe_ratio', 'market_cap', 'capitalization', 'eps', 'roe', 'inc_net_profit_year_on_year', 'volume']
total1 = pd.DataFrame()
total2 = pd.DataFrame()
total3 = pd.DataFrame()
total4 = pd.DataFrame()
for i in range(len(Year)):
    total1[Year[i]] = IC_A.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total2[Year[i]] = IC_SH50.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total3[Year[i]] = IC_HS300.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total4[Year[i]] = IC_ZZ500.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
x = np.array(range(len(Year)))
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total1.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;A&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total2.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;SH50&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total3.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;HS300&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total4.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;ZZ500&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
</code></pre>
<pre><code class="language-python">IC_A = abs(IC_A)#计算IC绝对值的平均值
IC_SH50 = abs(IC_SH50)
IC_HS300 = abs(IC_HS300)
IC_ZZ500 = abs(IC_ZZ500)
temp = pd.DataFrame()
temp['A'] = IC_A.mean()
temp['SH50'] = IC_SH50.mean()
temp['HS300'] = IC_HS300.mean()
temp['ZZ500'] = IC_ZZ500.mean()
fig.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
sns.heatmap(temp, annot=True, vmax=1, vmin = 0)
ax.set_title(&quot;IC ABS Mean&quot;, fontsize=21)
fig.show()

#分年度计算并可视化IC年度绝对值的平均值
Year= ['2014', '2015', '2016', '2017', '2018']
Fields = ['turnover_ratio', 'pe_ratio', 'market_cap', 'capitalization', 'eps', 'roe', 'inc_net_profit_year_on_year', 'volume']
total1 = pd.DataFrame()
total2 = pd.DataFrame()
total3 = pd.DataFrame()
total4 = pd.DataFrame()
for i in range(len(Year)):
    total1[Year[i]] = IC_A.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total2[Year[i]] = IC_SH50.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total3[Year[i]] = IC_HS300.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
    total4[Year[i]] = IC_ZZ500.iloc[i*len(explore1)/5:(i+1)*len(explore1)/5,:].mean()
x = np.array(range(len(Year)))
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total1.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;A&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total2.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;SH50&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total3.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;HS300&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()
fig = plt.figure(figsize=(15,6))
ax = fig.add_subplot(111)
for i in Fields:
    plt.bar(x, total4.loc[i], 0.3, label = i)
plt.xticks(range(len(Year)), Year)
ax.set_title(&quot;ZZ500&quot;, fontsize=21)
# 添加图例
plt.legend()
plt.show()

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Movie Industry Stocks Timing ]]></title>
        <id>https://yshuai99.github.io/post/movie-industry-stocks-timing/</id>
        <link href="https://yshuai99.github.io/post/movie-industry-stocks-timing/">
        </link>
        <updated>2021-06-15T15:37:57.000Z</updated>
        <summary type="html"><![CDATA[<p>This strategy is based on python 3.6 and jq module.</p>
]]></summary>
        <content type="html"><![CDATA[<p>This strategy is based on python 3.6 and jq module.</p>
<!-- more -->
<p>This strategy is developed based on jq module (joinquant.com)</p>
<p>In China, there are a lot of holidays between December and June, I will hold suitable stocks from movie industries during this time.</p>
<h2 id="code">code</h2>
<pre><code class="language-python">import jqdata


def initialize(context):
    set_option('use_real_price', True)
    set_benchmark('000300.XSHG')
    # R86 indicate the movie industry
    stocks = get_industry_stocks('R86')
    
    # Filter for suitable stocks
    fundamental_df = get_fundamentals(
        query(
            indicator.roe,
            indicator.gross_profit_margin,
            valuation.pb_ratio, valuation.code,cash_flow.subtotal_operate_cash_inflow           
        )
        .filter(
            valuation.code.in_ (stocks)
        )
        .filter(
            indicator.roe&gt;0
        )
        .filter(
            indicator.gross_profit_margin&gt;0.3
        )
        .filter(
            valuation.pb_ratio&lt;3
        )
        .filter(
            cash_flow.subtotal_operate_cash_inflow&gt;0
        )
        .order_by(
            valuation.pb_ratio.asc()
        )
        .limit(10)
        
    )
    g.stocks = fundamental_df['code']
    

def handle_data(context, data):
    if len(g.stocks)==0: 
        cash = context.portfolio.available_cash
    else:
        cash = context.portfolio.available_cash/len(g.stocks)
    
    hist = history(1,'1d','close',g.stocks)
 
    for security in g.stocks:
        today = context.current_dt
        current_price = hist[security][0]
        # Hold the stock during December to June
        if today.month == 12 and today.day &gt; 1 and cash &gt; current_price and context.portfolio.positions[security].closeable_amount == 0:
            order_value(security, cash)
            log.info(&quot;Buying %s&quot; % (security))
            
        elif today.month == 6 and today.day &gt; 12 and context.portfolio.positions[security].closeable_amount &gt; 0:
            order_target(security, 0)

            log.info(&quot;Selling %s&quot; % (security))
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hollween Effect Strategy]]></title>
        <id>https://yshuai99.github.io/post/hollween-effect-strategy/</id>
        <link href="https://yshuai99.github.io/post/hollween-effect-strategy/">
        </link>
        <updated>2021-06-15T15:30:50.000Z</updated>
        <summary type="html"><![CDATA[<p>The holloween effect strategy is based on python 3.6 and jq module.</p>
]]></summary>
        <content type="html"><![CDATA[<p>The holloween effect strategy is based on python 3.6 and jq module.</p>
<!-- more -->
<p>The strategy is developed based on jq module (joinquant.com)</p>
<blockquote></blockquote>
<p>The Halloween effect is a market-timing strategy based on the hypothesis that stocks perform better between Oct. 31 (Halloween) and May 1 than they do between the beginning of May through the end of October. (Investopedia.com)</p>
<h2 id="code">code</h2>
<pre><code class="language-python">def initialize(context):
    set_option('use_real_price', True)

    # Set up the trading stocks
    g.stocks = ['000001.XSHE','600000.XSHG','600019.XSHG','600028.XSHG','600030.XSHG','600036.XSHG','600519.XSHG','601398.XSHG','601857.XSHG','601988.XSHG']


def handle_data(context, data):
    cash = context.portfolio.available_cash / len(g.stocks)
    hist = history(1,'1d','close',g.stocks)
    for security in g.stocks:
        today = context.current_dt
        current_price = hist[security][0]
        # If the current time is larger than October 15th, buy it.
        if today.month == 10 and today.day &gt; 15 and cash &gt; current_price and context.portfolio.positions[security].closeable_amount == 0:
            order_value(security, cash)
            log.info(&quot;Buying %s&quot; % (security))
        # If the current time is larger than May 5th, then sell it
        elif today.month == 5 and today.day &gt; 15 and context.portfolio.positions[security].closeable_amount &gt; 0:
            order_target(security, 0)
            log.info(&quot;Selling %s&quot; % (security))
</code></pre>
]]></content>
    </entry>
</feed>